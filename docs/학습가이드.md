# 🎯 카나리 배포 실무 학습 가이드

실무에서 바로 적용할 수 있는 카나리 배포 시스템을 단계별로 학습하는 대화형 가이드입니다.

## 📋 학습 전 체크리스트

시작하기 전에 다음 항목을 확인하세요:

- ✅ Docker 및 Docker Compose 설치 완료
- ✅ K6 설치 완료 (`brew install k6` 또는 [공식 문서](https://k6.io/docs/getting-started/installation/) 참조)
- ✅ Git 저장소 클론 완료
- ✅ 8000-9090 포트 범위 사용 가능 확인

## 🚀 Phase 1: 기본 시스템 이해 및 구동

### Step 1.1: 전체 시스템 구동
```bash
# 전체 시스템 시작
docker-compose up -d

# 서비스 상태 확인
docker-compose ps

# 로그 모니터링 (별도 터미널)
docker compose logs -f nginx legacy-app-1 refactored-app-1
```

**✅ 완료 확인:**
- ✅ 모든 컨테이너가 `healthy` 상태
- ✅ NGINX 로드밸런서 접근 가능: http://localhost:8000/api/hello
- ✅ Prometheus 접근 가능: http://localhost:9090
- ✅ Grafana 접근 가능: http://localhost:3000 (admin/admin)

### Step 1.2: 기본 트래픽 분배 확인
```bash
# 기본 트래픽 분배 테스트
for i in {1..20}; do
  curl -s http://localhost:8000/api/version | jq '.version'
  sleep 1
done
```

**🔍 관찰할 점:**
- ✅ 대부분 요청이 "legacy" 버전으로 라우팅 (95%)
- ✅ 일부 요청이 "refactored" 버전으로 라우팅 (5%)
- ✅ Response 헤더에 `X-Upstream-Server` 정보 포함

---

## 🎛️ Phase 2: 수동 트래픽 제어 학습

### Step 2.1: 트래픽 가중치 조회
```bash
# 현재 트래픽 상태 확인
curl http://localhost:8000/api/traffic/status | jq .

# 배포 상태 확인
curl http://localhost:8000/api/traffic/canary/status | jq .
```

---

## 🤖 Phase 3: 자동 배포 시스템 학습

### Step 3.1: 자동 배포 시작
```bash
# 자동 배포 시작
curl -X POST http://localhost:8000/api/auto-deployment/start | jq .

# 상태 모니터링 (별도 터미널에서 실행)
watch -n 5 'curl -s http://localhost:8000/api/auto-deployment/dashboard | jq .'
```

### Step 3.2: SLI/SLO 메트릭 이해
```bash
# 현재 SLI/SLO 상태 확인
curl http://localhost:8000/api/auto-deployment/sli-slo | jq .

# SLI/SLO 설정 정보 확인
curl http://localhost:8000/api/auto-deployment/sli-slo/config | jq .
```

**🎯 핵심 메트릭:**
- [ ] **Error Rate**: 에러율 (목표: < 2%)
- [ ] **Response Time P95**: 95%ile 응답시간 (목표: < 1.0초)
- [ ] **Availability**: 가용성 (목표: > 99.9%)
- [ ] **Throughput**: 처리량 (목표: > 1 RPS)

### Step 3.3: 자동 배포 프로세스 관찰
자동 배포가 진행되는 동안 다음을 관찰하세요:

1. **Stage 1 (5%)**: 초기 카나리 트래픽
2. **Stage 2 (10%)**: 점진적 증가
3. **Stage 3 (25%)**: 본격적인 테스트
4. **Stage 4 (50%)**: 과반수 트래픽
5. **Stage 5 (100%)**: 완전 전환

**⏱️ 각 단계별 대기 시간:** 5분 (설정 가능)

---

## 📈 Phase 4: 부하 테스트 및 SLO 검증

### Step 4.1: K6 부하 테스트 실행
```bash
# 향상된 자동 배포 테스트 실행
k6 run k6-tests/enhanced-auto-deployment-test.js

# 기본 카나리 테스트 (병렬 실행)
k6 run k6-tests/phase1-basic-canary.js
```

---

## 🚨 Phase 5: 장애 시나리오 및 자동 롤백

### Step 5.1: 에러 상황 시뮬레이션
```bash
# 에러 시뮬레이션 엔드포인트로 트래픽 생성
for i in {1..100}; do
  curl -s http://localhost:8000/api/error-simulation
  sleep 0.5
done
```

### Step 5.2: 알람 및 롤백 관찰
```bash
# Alertmanager 상태 확인
curl http://localhost:9093/api/v2/alerts | jq .

# 자동 롤백 로그 확인
docker-compose logs webhook-handler | grep -i rollback
```

**🔥 롤백 트리거 조건:**
- [ ] 에러율 > 5% (2분 지속)
- [ ] 응답시간 P95 > 1.5초 (1분 지속)
- [ ] 가용성 < 99.9%

---

## 📊 Phase 6: 모니터링 및 대시보드 활용

### Step 6.1: Grafana 대시보드 설정
1. http://localhost:3000 접속 (admin/admin)
2. "Canary Deployment Logs" 대시보드 열기
3. 다음 패널들 확인:
   - [ ] 트래픽 분배 현황
   - [ ] 에러율 및 응답시간
   - [ ] 비즈니스 메트릭
   - [ ] 배포 진행 상황

### Step 6.2: Prometheus 쿼리 학습
```promql
# 에러율 계산
rate(nginx_http_requests_total{status=~"5.."}[2m]) / rate(nginx_http_requests_total[2m]) * 100

# 응답시간 P95
histogram_quantile(0.95, rate(nginx_http_request_duration_seconds_bucket[2m]))

# 버전별 트래픽 분배
sum by (upstream_addr) (rate(nginx_http_requests_total[1m]))

# 비즈니스 전환율
rate(business_orders_completed_total[5m]) / rate(business_orders_attempted_total[5m]) * 100
```

---

## 🎓 Phase 8: 고급 시나리오 및 실무 적용

### Step 8.1: 멀티 카나리 시나리오
```bash
# 여러 기능을 동시에 테스트하는 시나리오
k6 run k6-tests/phase4-multi-canary.js
```

### Step 8.2: 프로덕션 규모 테스트
```bash
# 대용량 트래픽 시뮬레이션
k6 run k6-tests/phase5-production-load.js
```

### Step 8.3: 복구 및 재배포 시나리오
```bash
# 롤백 후 재배포 테스트
curl -X POST http://localhost:8000/api/traffic/canary/rollback | jq .
sleep 30
curl -X POST http://localhost:8000/api/auto-deployment/start | jq .
```

---

## ✅ 학습 완료 체크리스트

### 기본 이해도
- [ ] 카나리 배포의 개념과 장점 이해
- [ ] NGINX 로드밸런서 설정 이해
- [ ] Docker Compose 기반 마이크로서비스 구조 이해
- [ ] Prometheus/Grafana 모니터링 스택 이해

### 실무 활용 능력
- [ ] 수동 트래픽 제어 및 조정 가능
- [ ] SLI/SLO 정의 및 임계값 설정 가능
- [ ] 자동 배포 시스템 구성 및 관리 가능
- [ ] 장애 감지 및 자동 롤백 시스템 이해

### 고급 기능
- [ ] 비즈니스 메트릭 기반 의사결정 가능
- [ ] A/B 테스트 설계 및 결과 분석 가능
- [ ] 기능 플래그 기반 점진적 출시 가능
- [ ] 멀티 환경 배포 전략 수립 가능

### 모니터링 및 분석
- [ ] Grafana 대시보드 커스터마이징 가능
- [ ] Prometheus 쿼리 작성 가능
- [ ] 알람 규칙 정의 및 웹훅 설정 가능
- [ ] 장애 분석 및 포스트모템 작성 가능

---

## 🚀 다음 단계 제안

학습 완료 후 다음 단계로 발전시킬 수 있습니다:

1. **다중 환경 적용**: Dev/Stage/Prod 환경별 설정
2. **클라우드 배포**: AWS/GCP/Azure에서 실제 운영
3. **GitOps 통합**: ArgoCD/Flux와 연동
4. **서비스 메시 적용**: Istio/Linkerd 기반 트래픽 관리
5. **고급 관찰성**: Jaeger/Zipkin 분산 추적 연동

---

## 🆘 문제 해결 가이드

### 일반적인 문제들

**Q1: 컨테이너가 시작되지 않아요**
```bash
# 포트 충돌 확인
netstat -tulpn | grep :8000

# 로그 확인
docker-compose logs [서비스명]

# 완전 재시작
docker-compose down -v && docker-compose up -d
```

**Q2: 메트릭이 수집되지 않아요**
```bash
# Prometheus 타겟 상태 확인
curl http://localhost:9090/api/v1/targets

# 애플리케이션 메트릭 엔드포인트 확인
curl http://localhost:8080/actuator/metrics
```

**Q3: 자동 배포가 시작되지 않아요**
```bash
# 현재 배포 상태 확인
curl http://localhost:8000/api/traffic/canary/status | jq .

# 스케줄러 로그 확인
docker-compose logs legacy-app-1 | grep AutoDeploymentScheduler
```

---

**🎉 축하합니다!** 이 가이드를 완료하셨다면 실무에서 카나리 배포 시스템을 설계하고 운영할 수 있는 역량을 갖추게 되었습니다.

실제 프로덕션 적용 시에는 조직의 요구사항에 맞게 임계값과 배포 단계를 조정하여 사용하세요.